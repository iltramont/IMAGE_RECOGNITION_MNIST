{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b04cade-147c-4710-871c-45f16afc7b93",
   "metadata": {},
   "source": [
    "# Models\n",
    "In this notebook we will build models with the hyperparameters obtained in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc421e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucat\\anaconda3\\envs\\AI_LAB\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SAVE_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363b836",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9677751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea813e90-2392-4976-ba1e-a341c516db23",
   "metadata": {},
   "source": [
    "## Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3cec04-2041-47ea-ae0b-6cc1818ddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dbe2c",
   "metadata": {},
   "source": [
    "## Scaling between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b69362-e7e3-4333-9c4e-9bcccca71586",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc = x_train / 255\n",
    "x_test_sc = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a06114",
   "metadata": {},
   "source": [
    "## PCA\n",
    "We will use a 95% PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22086097-e8e9-45a6-83bc-8f5ff1081761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 784\n",
      "Number of principal components: 331\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(0.95)\n",
    "\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)\n",
    "\n",
    "x_train_pca = pca.fit_transform(x_train_std)\n",
    "x_test_pca = pca.transform(x_test_std)\n",
    "\n",
    "print(\"Original number of features:\", x_train_std.shape[1])\n",
    "print(\"Number of principal components:\", pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51688168",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbfca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN complete\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4, weights=\"distance\", n_jobs=-1).fit(x_train_sc, y_train)\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=4, weights=\"distance\", n_jobs=-1).fit(x_train_pca, y_train)\n",
    "print(\"KNN complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec66ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest complete\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\", random_state=25, n_jobs=-1).fit(x_train_sc, y_train)\n",
    "rf_pca = RandomForestClassifier(criterion=\"entropy\", max_features=\"sqrt\", random_state=25, n_jobs=-1).fit(x_train_pca, y_train)\n",
    "print(\"Random Forest complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e7b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression complete\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty=\"l1\", solver=\"saga\", multi_class=\"multinomial\").fit(x_train_sc, y_train)\n",
    "lr_pca = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", multi_class=\"multinomial\").fit(x_train_pca, y_train)\n",
    "print(\"Logistic Regression complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa3c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"knn\": knn,\n",
    "    \"knn_pca\": knn_pca,\n",
    "    \"lr\": lr,\n",
    "    \"lr_pca\": lr_pca,\n",
    "    \"rf\": rf,\n",
    "    \"rf_pca\": rf_pca,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa01b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_MODELS:\n",
    "    # Save models with pickle\n",
    "    for key, m in models.items():\n",
    "        file_name = key + \".pkl\"\n",
    "        pickle.dump(m, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64c28a",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3c03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dict()\n",
    "predictions[\"groundtruth\"] = y_test\n",
    "for key in models.keys():\n",
    "    if \"_pca\" in key:\n",
    "        predictions[key] = models[key].predict(x_test_pca)\n",
    "    else:\n",
    "        predictions[key] = models[key].predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2494fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>knn</th>\n",
       "      <th>knn_pca</th>\n",
       "      <th>lr</th>\n",
       "      <th>lr_pca</th>\n",
       "      <th>rf</th>\n",
       "      <th>rf_pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      groundtruth  knn  knn_pca  lr  lr_pca  rf  rf_pca\n",
       "0               7    7        7   7       7   7       7\n",
       "1               2    2        2   2       2   2       2\n",
       "2               1    1        1   1       1   1       1\n",
       "3               0    0        0   0       0   0       0\n",
       "4               4    4        4   4       4   4       4\n",
       "...           ...  ...      ...  ..     ...  ..     ...\n",
       "9995            2    2        2   2       2   2       2\n",
       "9996            3    3        3   3       3   3       3\n",
       "9997            4    4        4   4       4   4       4\n",
       "9998            5    5        5   5       5   5       5\n",
       "9999            6    6        6   6       6   6       6\n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "display(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44498272-bc0e-4dbf-8d5c-ec123c2c231f",
   "metadata": {},
   "source": [
    "## Save predictions with csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5def72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "predictions_df.to_csv(\"predictions_mnist.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
